"""
scripts/04_generate_paper_results.py
Generate all tables and figures for paper submission
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def generate_comparison_table():
    """Generate LaTeX table for paper"""
    comparison = pd.read_csv('results/method_comparison.csv')
    
    # Format for LaTeX
    latex_table = comparison.to_latex(
        index=False,
        float_format="%.2f",
        caption="Performance comparison of hierarchical agent vs. baselines on UK grid data (June-Nov 2024)",
        label="tab:comparison"
    )
    
    with open('results/paper/table_comparison.tex', 'w') as f:
        f.write(latex_table)
    
    print("âœ“ LaTeX table generated: results/paper/table_comparison.tex")

def statistical_significance():
    """Perform t-tests between methods"""
    
    # Load daily rewards for each method
    hier = pd.read_csv('results/validation_hierarchical_latest.csv')
    rule = pd.read_csv('results/validation_rule_based.csv')
    
    hier_daily = hier.groupby(hier['datetime'].dt.date)['total_reward'].sum()
    rule_daily = rule.groupby(rule['datetime'].dt.date)['total_reward'].sum()
    
    # T-test
    t_stat, p_value = stats.ttest_ind(hier_daily, rule_daily)
    
    print(f"\n{'='*60}")
    print("STATISTICAL SIGNIFICANCE TEST")
    print(f"{'='*60}")
    print(f"Hierarchical mean: Â£{hier_daily.mean():.2f} Â± Â£{hier_daily.std():.2f}")
    print(f"Rule-based mean:   Â£{rule_daily.mean():.2f} Â± Â£{rule_daily.std():.2f}")
    print(f"\nT-statistic: {t_stat:.4f}")
    print(f"P-value: {p_value:.6f}")
    
    if p_value < 0.05:
        print("âœ“ Difference is statistically significant (p < 0.05)")
    else:
        print("âœ— Difference is NOT statistically significant")
    
    return {'t_stat': t_stat, 'p_value': p_value}

if __name__ == "__main__":
    print("Generating paper results...")
    
    # Create output directory
    Path('results/paper').mkdir(parents=True, exist_ok=True)
    
    # Generate table
    generate_comparison_table()
    
    # Statistical tests
    stats_results = statistical_significance()
    
    print("\nâœ“ All paper results generated!")
```

---

## **ðŸ“ FINAL DIRECTORY STRUCTURE**
```
batteryCLASS/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                    # Original downloads
â”‚   â”‚   â”œâ”€â”€ demanddata_2023.csv
â”‚   â”‚   â”œâ”€â”€ demanddata_2024.csv
â”‚   â”‚   â”œâ”€â”€ demanddata_2025.csv
â”‚   â”‚   â””â”€â”€ electricitypricesdataset201125.xlsx
â”‚   â”œâ”€â”€ processed/                              # Combined datasets
â”‚   â”‚   â””â”€â”€ uk_battery_dispatch_complete_data.csv
â”‚   â””â”€â”€ figures/                                # EDA visualizations
â”‚       â””â”€â”€ data_exploration.png
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ commander/
â”‚   â”‚   â”œâ”€â”€ best_model.pth                      # Your trained commander
â”‚   â”‚   â””â”€â”€ config.json
â”‚   â”œâ”€â”€ tactician/
â”‚   â”‚   â”œâ”€â”€ best_model.pth                      # Your trained tactician
â”‚   â”‚   â””â”€â”€ config.json
â”‚   â””â”€â”€ checkpoints/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ validate_hierarchical.py            # Main validation
â”‚   â””â”€â”€ baselines/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ rule_based.py                       # Rule-based baseline
â”‚       â””â”€â”€ single_level_rl.py                  # Flattened RL baseline
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_preprocess_data.py                   # Data combination
â”‚   â”œâ”€â”€ 02_explore_data.py                      # EDA
â”‚   â”œâ”€â”€ 03_compare_baselines.py                 # Method comparison
â”‚   â””â”€â”€ 04_generate_paper_results.py            # Paper tables/figures
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb               # Interactive EDA
â”‚   â”œâ”€â”€ 02_results_analysis.ipynb               # Results deep-dive
â”‚   â””â”€â”€ 03_visualization.ipynb                  # Custom plots
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ validation_hierarchical_*.csv           # Your agent results
â”‚   â”œâ”€â”€ validation_rule_based.csv               # Rule-based results
â”‚   â”œâ”€â”€ validation_single_level.csv             # Single-level results
â”‚   â”œâ”€â”€ method_comparison.csv                   # Comparison table
â”‚   â”œâ”€â”€ metrics_hierarchical.json               # Metrics summary
â”‚   â”œâ”€â”€ figures/                                # All visualizations
â”‚   â”‚   â”œâ”€â”€ validation_visualization.png
â”‚   â”‚   â”œâ”€â”€ method_comparison.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ paper/                                  # Paper-ready outputs
â”‚       â”œâ”€â”€ table_comparison.tex
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore